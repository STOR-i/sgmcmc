% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sgld.R
\name{sgldcv}
\alias{sgldcv}
\title{Stochastic Gradient Langevin Dynamics with Control Variates}
\usage{
sgldcv(logLik, dataset, params, stepsize, optStepsize, logPrior = NULL,
  minibatchSize = 0.01, nIters = 10^4, nItersOpt = 10^4, verbose = TRUE)
}
\arguments{
\item{logLik}{function which takes parameters and dataset 
(list of tensorflow variables and placeholders respectively) as input. 
It should return a tensorflow expression which defines the log likelihood of the model.}

\item{dataset}{list of numeric R arrays which defines the datasets for the problem.
The names in the list should correspond to those referred to in the logLik and logPrior functions}

\item{params}{list of numeric R arrays which define the starting point of each parameter.
The names in the list should correspond to those referred to in the logLik and logPrior functions}

\item{stepsize}{list of stepsizes corresponding to the SGLD stepsizes for each parameter
The names in the list should correspond to those in params.
Alternatively specify a single float to use that stepsize for all parameters.}

\item{optStepsize}{stepsize for optimization to find MAP estimates of parameters. Assumed float.}

\item{logPrior}{function which takes parameters (list of tensorflow variables) as input.
The function should return a tensorflow tensor which defines the log prior of the model.
Optional. Default uninformative improper prior.}

\item{minibatchSize}{either as proportion of dataset size or actual size, assumed float or int.
Optional. Default 0.01.}

\item{nIters}{integer, number of iterations of SGLD to perform, optional, default 10^4.}

\item{nItersOpt}{integer, number of iterations of initial optimization to perform, 
optional, default 10^4.}

\item{verbose}{Boolean, whether to print algorithm progress or not, default TRUE.}
}
\value{
List of arrays for each parameter containing the MCMC chain.
 Dimension of the form (nIters,paramDim1,paramDim2,...)
}
\description{
Simulates from the posterior defined by the functions logLik and logPrior using
 stochastic gradient Langevin Dynamics with an improved gradient estimate using Control Variates.
 The function uses TensorFlow, so needs Tensorflow for python installed.
}
\references{
\itemize{
 \item \href{https://arxiv.org/pdf/1706.05439.pdf}{
 Baker, J., Fearnhead, P., Fox, E. B., and Nemeth, C. (2017).
 Control variates for stochastic gradient MCMC. ArXiv preprint arXiv:1706.05439.}
 \item \href{http://people.ee.duke.edu/~lcarin/398_icmlpaper.pdf}{
 Welling, M., and Teh, Y. W. (2011). Bayesian learning via stochastic gradient Langevin dynamics. 
 ICML (pp. 681-688).} }
}
