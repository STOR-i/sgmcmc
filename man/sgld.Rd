% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sgld.R
\name{sgld}
\alias{sgld}
\title{Stochastic Gradient Langevin Dynamics}
\usage{
sgld(logLik, dataset, params, stepsize, logPrior = NULL,
  minibatchSize = 0.01, nIters = 10^4L, verbose = TRUE, seed = NULL)
}
\arguments{
\item{logLik}{function which takes parameters and dataset 
(list of TensorFlow variables and placeholders respectively) as input. 
It should return a TensorFlow expression which defines the log likelihood of the model.}

\item{dataset}{list of numeric R arrays which defines the datasets for the problem.
The names in the list should correspond to those referred to in the logLik and logPrior functions}

\item{params}{list of numeric R arrays which define the starting point of each parameter.
The names in the list should correspond to those referred to in the logLik and logPrior functions}

\item{stepsize}{list of numeric values corresponding to the SGLD stepsizes for each parameter
The names in the list should correspond to those in params.
Alternatively specify a single numeric value to use that stepsize for all parameters.}

\item{logPrior}{optional. Default uninformative improper prior.
Function which takes parameters (list of TensorFlow variables) as input.
The function should return a TensorFlow tensor which defines the log prior of the model.}

\item{minibatchSize}{optional. Default 0.01.
Numeric or integer value that specifies amount of dataset to use at each iteration 
either as proportion of dataset size (if between 0 and 1) or actual magnitude (if an integer).}

\item{nIters}{optional. Default 10^4L. Integer specifying number of iterations to perform.}

\item{verbose}{optional. Default TRUE. Boolean specifying whether to print algorithm progress}

\item{seed}{optional. Default NULL. Numeric seed for random number generation. The default
does not declare a seed for the TensorFlow session.}
}
\value{
Returns list of arrays for each parameter containing the MCMC chain.
 Dimension of the form (nIters,paramDim1,paramDim2,...)
}
\description{
Simulates from the posterior defined by the functions logLik and logPrior using
 stochastic gradient Langevin Dynamics. The function uses TensorFlow, so needs
 TensorFlow for python installed.
}
\examples{
\dontrun{
# Simulate from a Normal Distribution with uninformative prior
dataset = list("x" = rnorm(1000))
params = list("theta" = 0)
logLik = function(params, dataset) { 
    distn = tf$contrib$distributions$Normal(params$theta, 1)
    return(tf$reduce_sum(distn$log_prob(dataset$x)))
}
stepsize = list("theta" = 1e-4)
output = sgld(logLik, dataset, params, stepsize)
# For more examples see vignettes
}
}
\references{
\itemize{\item \href{http://people.ee.duke.edu/~lcarin/398_icmlpaper.pdf}{
 Welling, M., and Teh, Y. W. (2011). Bayesian learning via stochastic gradient Langevin dynamics. 
 ICML (pp. 681-688).}}
}
