% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sgld.R
\name{sgld}
\alias{sgld}
\title{Stochastic Gradient Langevin Dynamics}
\usage{
sgld(logLik, logPrior, dataset, params, stepsize, n, nIters = 10^4,
  verbose = TRUE)
}
\arguments{
\item{logLik}{function which takes parameters and dataset 
(list of tensorflow variables and placeholders respectively) as input. 
It should return a tensorflow expression which defines the log likelihood of the model.}

\item{logPrior}{function which takes parameters and dataset 
(list of tensorflow variables and placeholders respectively) as input. 
The function should return a tensorflow tensor which defines the log prior of the model.}

\item{dataset}{list of R arrays which defines the datasets for the problem.
The names in the list should correspond to those referred to in the logLik and logPrior functions}

\item{params}{list of R arrays which define the starting point of each parameter.
The names in the list should correspond to those referred to in the logLik and logPrior functions}

\item{stepsize}{list of stepsizes corresponding to the SGLD stepsizes for each parameter
The names in the list should correspond to those in params.}

\item{n}{minibatch size, assumed integer.}

\item{nIters}{number of iterations of SGLD to perform, optional, assumed integer, default 10^4.}

\item{verbose}{whether to print algorithm progress or not, assumed BOOLEAN, default TRUE.}
}
\value{
List of arrays for each parameter containing the MCMC chain.
 Dimension of the form (nIters,paramDim1,paramDim2,...)
}
\description{
Simulates from the posterior defined by the functions logLik & logPrior using
 stochastic gradient Langevin Dynamics. The function uses TensorFlow, so needs
 Tensorflow for python installed.
}
\references{
\itemize{\item \href{http://people.ee.duke.edu/~lcarin/398_icmlpaper.pdf}{
 Welling, M., & Teh, Y. W. (2011). Bayesian learning via stochastic gradient Langevin dynamics. 
 ICML (pp. 681-688).}}
}
