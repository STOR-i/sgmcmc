<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Worked Example: Simulate from a Multivariate Gaussian • sgmcmc</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">sgmcmc</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/sgmcmc.html">Get Started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/gaussMixture.html">Worked Example: Simulate from a Gaussian Mixture</a>
    </li>
    <li>
      <a href="../articles/logisticRegression.html">Worked Example: Logistic Regression</a>
    </li>
    <li>
      <a href="../articles/mvGauss.html">Worked Example: Simulate from a Multivariate Gaussian</a>
    </li>
    <li>
      <a href="../articles/nn.html">Advanced Example: Simulate from a Bayesian Neural Network -- Storage Constraints</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/STOR-i/sgmcmc">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Worked Example: Simulate from a Multivariate Gaussian</h1>
                        <h4 class="author">Jack Baker</h4>
            
          </div>

    
    
<div class="contents">
<p>In this example we use the package to infer the mean of a 2d Gaussian using <a href="http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Welling_398.pdf">stochastic gradient Langevin dynamics</a>. So we assume we have independent and identically distributed data <span class="math inline">\(x_1, \dots, x_N\)</span> with <span class="math inline">\(X_i | \theta \sim N( \theta, I_2 )\)</span>, and we want to infer <span class="math inline">\(\theta\)</span>.</p>
<p>First, let’s simulate the data with the following code, we set <span class="math inline">\(N\)</span> to be <span class="math inline">\(10^4\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sgmcmc)
<span class="kw">library</span>(MASS)
<span class="co"># Declare number of observations</span>
N =<span class="st"> </span><span class="dv">10</span>^<span class="dv">4</span>
<span class="co"># Set theta to be 0 and simulate the data</span>
theta =<span class="st"> </span><span class="kw">c</span>( <span class="dv">0</span>, <span class="dv">0</span> )
Sigma =<span class="st"> </span><span class="kw">diag</span>(<span class="dv">2</span>)
<span class="kw">set.seed</span>(<span class="dv">13</span>)
X =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/MASS/topics/mvrnorm">mvrnorm</a></span>( N, theta, Sigma )
dataset =<span class="st"> </span><span class="kw">list</span>(<span class="st">"X"</span> =<span class="st"> </span>X)</code></pre></div>
<p>In the last line we defined the dataset as it will be input to the relevant <code>sgmcmc</code> function. A lot of the inputs to functions in <code>sgmcmc</code> are defined as lists. This improves flexibility by enabling models to be specified with multiple parameters, datasets and allows separate tuning constants to be set for each parameter. We assume that observations are always accessed on the first dimension of each object, i.e. the point <span class="math inline">\(x_i\)</span> is located at <code>X[i,]</code> rather than <code>X[,i]</code>. Similarly the observation <span class="math inline">\(i\)</span> from a 3d object <code>Y</code> would be located at <code>Y[i,,]</code>.</p>
<p>The parameters are declared very similarly, but this time the value associated with each entry is its starting point. We have one parameter <code>theta</code>, which we’ll just start at 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">params =<span class="st"> </span><span class="kw">list</span>( <span class="st">"theta"</span> =<span class="st"> </span><span class="kw">c</span>( <span class="dv">0</span>, <span class="dv">0</span> ) )</code></pre></div>
<p>Now we’ll define the functions <code>logLik</code> and <code>logPrior</code>. It should now become clear why the list names come in handy. The function <code>logLik</code> should take two parameters as input: <code>params</code> and <code>dataset</code>. These parameters will be lists with the same names as those you defined for <code>params</code> and <code>dataset</code> earlier. There is one difference though, the objects in the lists will have automatically been converted to <code>TensorFlow</code> objects for you. The <code>params</code> list will contain <code>TensorFlow</code> tensor variables; the <code>dataset</code> list will contain <code>TensorFlow</code> placeholders. The <code>logLik</code> function should take these lists as input and return the value of the log-likelihood function as a tensor at point <code>params</code> given data <code>dataset</code>. The function should do this using <code>TensorFlow</code> operations, as this allows the gradient to be automatically calculated; it also allows the wide range of distribution objects as well as matrix operations that <code>TensorFlow</code> provides to be taken advantage of. A tutorial of <code>TensorFlow</code> for <code>R</code> is beyond the scope of this article, for more details we refer the reader to the website of <a href="https://tensorflow.rstudio.com/">TensorFlow for R</a>. With this in place we can define the <code>logLik</code> function as follows</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">logLik =<span class="st"> </span>function( params, dataset ) {
    <span class="co"># Declare distribution of each observation</span>
    SigmaDiag =<span class="st"> </span><span class="kw">c</span>( <span class="dv">1</span>, <span class="dv">1</span> )
    baseDist =<span class="st"> </span>tf$contrib$distributions$<span class="kw">MultivariateNormalDiag</span>( params$theta, SigmaDiag )
    <span class="co"># Declare log-likelihood function and return</span>
    logLik =<span class="st"> </span>tf$<span class="kw">reduce_sum</span>( baseDist$<span class="kw">log_prob</span>( dataset$X ) )
    <span class="kw">return</span>( logLik )
}</code></pre></div>
<p>So this function basically states that our likelihood is <span class="math inline">\(\sum_{i=1}^N \log \mathcal N( x_i | \theta, I_2 )\)</span>, where <span class="math inline">\(\mathcal N( x | \mu, \Sigma )\)</span> is a Gaussian density at <span class="math inline">\(x\)</span> with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\Sigma\)</span>. Most of the time just specifying the constants in these functions, such as <code>SigmaDiag</code> as <code>R</code> objects will be fine. But there are sometimes issues when these constants get automatically converted to <code>tf$float64</code> objects by <code>TensorFlow</code> rather than <code>tf$float32</code>. If you run into errors involving <code>tf$float64</code> then force the constants to be input as <code>tf$float32</code> by using <code>SigmaDiag = tf$constant( c( 1, 1 ), dtype = tf$float32 )</code>.</p>
<p>Next we want to define our log-prior density, which we assume is <span class="math inline">\(\log p( \theta_j ) = \log \mathcal N(\theta_j | 0,10)\)</span>, for each dimension <span class="math inline">\(j\)</span> of <span class="math inline">\(\theta\)</span>. Similar to <code>logLik</code>, <code>logPrior</code> is defined as a function with input <code>params</code>. In our case the definition is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">logPrior =<span class="st"> </span>function( params ) {
    baseDist =<span class="st"> </span>tf$contrib$distributions$<span class="kw">Normal</span>( <span class="dv">0</span>, <span class="dv">10</span> )
    logPrior =<span class="st"> </span>tf$<span class="kw">reduce_sum</span>( baseDist$<span class="kw">log_prob</span>( params$theta ) )
    <span class="kw">return</span>( logPrior )
}</code></pre></div>
<p>Before we begin running our SGLD algorithm, we need to specify the stepsize and minibatch size. A stepsize is required for each parameter, so this must be a list of numbers with names that are exactly the same as each of the parameters. The minibatch size is simply a number that is less than <span class="math inline">\(N\)</span>, or a number between 0 and 1 which will be taken to be the proportion of <span class="math inline">\(N\)</span>. It specifies how many observations are used in each iteration of SGMCMC, it is a trade off between accuracy and speed. The default is <code>minibatchSize = 0.01</code>, we’ll set it to be 100.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">stepsize =<span class="st"> </span><span class="kw">list</span>( <span class="st">"theta"</span> =<span class="st"> </span><span class="fl">1e-5</span> )
n =<span class="st"> </span><span class="dv">100</span></code></pre></div>
<p>The stepsize parameters may require a bit of tuning before you get good results. The shorthand <code>stepsize = 1e-5</code> can be used, which would set the stepsize of all parameters to be <code>1e-5</code>.</p>
<p>Now we can run our SGLD algorithm using the <code>sgmcmc</code> function <code>sgld</code>, which returns a list of Markov chains for each parameter as output. To make the results reproducible we’ll set the seed to 13. Use the argument <code>verbose = FALSE</code> to hide the output of the function</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chains =<span class="st"> </span><span class="kw"><a href="../reference/sgld.html">sgld</a></span>( logLik, dataset, params, stepsize, <span class="dt">logPrior =</span> logPrior, <span class="dt">minibatchSize =</span> n, 
              <span class="dt">verbose =</span> <span class="ot">FALSE</span>, <span class="dt">seed =</span> <span class="dv">13</span> )</code></pre></div>
<p>Finally we’ll plot the results after removing burn-in</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
burnIn =<span class="st"> </span><span class="dv">10</span>^<span class="dv">3</span>
thetaOut =<span class="st"> </span><span class="kw">as.data.frame</span>( chains$theta[-<span class="kw">c</span>(<span class="dv">1</span>:burnIn),] )
<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>( thetaOut, <span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>( <span class="dt">x =</span> V1, <span class="dt">y =</span> V2 ) ) +
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_density_2d">stat_density2d</a></span>( <span class="dt">size =</span> <span class="fl">1.5</span> )</code></pre></div>
<p><img src="mvGauss_files/figure-html/unnamed-chunk-9-1.png" width="672"></p>
<p>There are lots of other sgmcmc algorithms implemented in exactly the same way, such as <code>sghmc</code> and <code>sgnht</code>; as well as their <a href="https://arxiv.org/pdf/1705.05439.pdf">control variate counterparts</a> (<code>sgldcv</code>, <code>sghmccv</code> and <code>sgnhtcv</code>) for improved efficiency, which take the additional small numeric input <code>optStepsize</code>, the stepsize of the initial optimization step to find the MAP parameters.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by <a href="http://lancs.ac.uk/~bakerj1/">Jack Baker</a>, <a href="http://www.lancs.ac.uk/~nemeth/">Christopher Nemeth</a>, <a href="http://www.maths.lancs.ac.uk/~fearnhea/">Paul Fearnhead</a>, <a href="https://homes.cs.washington.edu/~ebfox/">Emily B. Fox</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
